{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 14:36:11.727 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-18 14:36:12.336 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-18 14:36:12.337 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-18 14:36:12.338 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-18 14:36:12.625 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/compomics/miniconda3/envs/publicdata/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-18 14:36:12.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import io\n",
    "from ftplib import FTP\n",
    "import os\n",
    "import subprocess\n",
    "#set streamlit wide\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "\n",
    "# Function to get the SDRF annotation count\n",
    "def fetch_data():\n",
    "    sdrfs_url = \"https://www.ebi.ac.uk/pride/ws/archive/v2/search/projects?keyword=sdrf\"\n",
    "    all_pxds_url = \"https://www.ebi.ac.uk/pride/ws/archive/v2/search/projects?\"\n",
    "    \n",
    "    number_sdrfs = int(requests.get(sdrfs_url).headers['total_records'])\n",
    "    number_pxds = int(requests.get(all_pxds_url).headers['total_records'])\n",
    "    \n",
    "    return number_sdrfs, number_pxds\n",
    "\n",
    "# Function to create the donut chart\n",
    "def plot_donut_chart(number_sdrfs, number_pxds):\n",
    "    annotated = number_sdrfs\n",
    "    not_annotated = number_pxds - number_sdrfs\n",
    "    labels = ['SDRF-annotated', 'Not annotated']\n",
    "    sizes = [annotated, not_annotated]\n",
    "    colors = ['orange', 'lightgrey']\n",
    "\n",
    "    # Create the donut chart using Plotly\n",
    "    fig = px.pie(\n",
    "        names=labels,\n",
    "        values=sizes,\n",
    "        color=labels,\n",
    "        color_discrete_map={\"SDRF-annotated\": \"orange\", \"Not annotated\": \"lightgrey\"},\n",
    "        hole=0.4,\n",
    "        labels={'labels': 'Status'},\n",
    "        title=f\"PRIDE Projects with SDRF Annotation: {annotated}/{number_pxds}\"\n",
    "    )\n",
    "\n",
    "    # Update chart layout for styling\n",
    "    fig.update_traces(textinfo='percent+label', pull=[0.1, 0])\n",
    "    # fig.update_layout(margin=dict(t=20, b=20, l=20, r=20))  # Adjust margins\n",
    "\n",
    "    # Show the plot in Streamlit\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "\n",
    "# Function to get SDRF FTP link from project accession\n",
    "def get_sdrf_ftp(pxd, df):\n",
    "    #first try if it's an indexed SDRF\n",
    "    #get publicationDate from df\n",
    "    publication_date = df[df['accession'] == pxd]['publicationDate'].values[0]\n",
    "    year = publication_date.split(\"-\")[0]\n",
    "    month = publication_date.split(\"-\")[1]\n",
    "    for fname in [\"sdrf.tsv\", \"sdrf.txt\"]:\n",
    "        ftp_link = f\"ftp://ftp.pride.ebi.ac.uk/pride/data/archive/{year}/{month}/{pxd}/{fname}\"\n",
    "        try:\n",
    "            sdrf_file = load_sdrf_from_ftp(ftp_link)\n",
    "            print(f\"{fname} found and loaded.\")\n",
    "            return ftp_link\n",
    "        except Exception as e:\n",
    "            #this only works if it's a non-indexed SDRF\n",
    "            files_url = f\"https://www.ebi.ac.uk/pride/ws/archive/v2/projects/{pxd}/files\"\n",
    "            response = requests.get(files_url)\n",
    "            files = response.json()\n",
    "            for f in files:\n",
    "                if 'sdrf' in f['fileName'].lower():\n",
    "                    ftp_link = next((loc['value'] for loc in f['publicFileLocations']\n",
    "                                    if loc['name'] == 'FTP Protocol'), None)\n",
    "                    if ftp_link:\n",
    "                        return ftp_link\n",
    "            return None\n",
    "\n",
    "def load_sdrf_from_ftp(ftp_link):\n",
    "    \"\"\"\n",
    "    Download an SDRF file from a given FTP link and return it as a pandas DataFrame.\n",
    "    Supports .tsv, .txt, .csv, and .xlsx files.\n",
    "    \"\"\"\n",
    "    # Parse FTP path\n",
    "    ftp_root = \"ftp.pride.ebi.ac.uk\"\n",
    "    path_parts = ftp_link.replace(f\"ftp://{ftp_root}/\", \"\").split(\"/\")\n",
    "    directory = \"/\".join(path_parts[:-1])\n",
    "    filename = path_parts[-1]\n",
    "    extension = os.path.splitext(filename)[-1].lower()\n",
    "\n",
    "    # Connect and download file to memory\n",
    "    ftp = FTP(ftp_root)\n",
    "    ftp.login()\n",
    "    ftp.cwd(directory)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    ftp.retrbinary(f\"RETR {filename}\", buffer.write)\n",
    "    ftp.quit()\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Read based on file extension\n",
    "    if extension in [\".tsv\", \".txt\"]:\n",
    "        return pd.read_csv(buffer, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "    elif extension == \".csv\":\n",
    "        return pd.read_csv(buffer, encoding=\"ISO-8859-1\")\n",
    "    elif extension == \".xlsx\":\n",
    "        return pd.read_excel(buffer)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {extension}\")\n",
    "\n",
    "def validate_sdrf(file_path):\n",
    "    \"\"\"Runs SDRF validation and returns success status & messages.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"parse_sdrf\", \"validate-sdrf\", \"--sdrf_file\", file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False  # Prevent exception on failure\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout.strip()\n",
    "        else:\n",
    "            return False, result.stdout.strip()\n",
    "    except FileNotFoundError:\n",
    "        return None, \"SDRF validation tool not found. Install `sdrf-pipelines` via `pip install sdrf-pipelines`.\"\n",
    "\n",
    "\n",
    "\n",
    "# Fetch the data and show donut chart\n",
    "number_sdrfs, number_pxds = fetch_data()\n",
    "plot_donut_chart(number_sdrfs, number_pxds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proj in all_projects:\n",
    "    pxd = proj['accession']\n",
    "    files = requests.get(f\"https://www.ebi.ac.uk/pride/ws/archive/v2/projects/{pxd}/files\").json()\n",
    "    for f in files:\n",
    "        if 'sdrf' in f['fileName'].lower():  # matches 'plasma_sdrf', 'mysdrf.tsv', etc.\n",
    "            # Handle as SDRF file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "publicdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
